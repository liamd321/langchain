{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6800cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run these in your environment for this doc to work\n",
    "#pip install gensim\n",
    "#pip install --upgrade plotly nbformat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c81491a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "# Embeddings\n",
    "\n",
    "This document will serve as less of a [tutorial](https://diataxis.fr/tutorials/) and more of an [explanation](https://diataxis.fr/explanation/) of what embeddings are.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cbf519",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "### LLM Embeddings <a class=\"anchor\" id=\"embeddings\"></a>\n",
    "Now, assuming you have a basic idea of embeddings as numerical representations of words (tokens), you might be wondering how we get these embeddings to contain sort of semantic meaning. \n",
    "Remember that this is needed in order for our RAG machine to be able to find the relevant piece of data (chunk) to answer your question. The key lies in training another model to transform our words (technically [tokens](https://medium.com/thedeephub/all-you-need-to-know-about-tokenization-in-llms-7a801302cf54)) into multi-dimensional numbers as tensors (essentially n-dimensional vectors), that are closer to eachother the more similar they are in meaning. We also want the representations to have meaning in combination, a classic example of this is looking at embeddings in a dimensional space that we can think about easily, like 3D:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e050e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        </script>\n",
       "        <script type=\"module\">import \"https://cdn.plot.ly/plotly-3.1.1.min\"</script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-3.1.1.min.js\" integrity=\"sha256-HUEFyfiTnZJxCxur99FjbKYTvKSzwDaD3/x5TqHpFu4=\" crossorigin=\"anonymous\"></script>                <div id=\"b8d3efdd-9053-4867-b3e2-5e1606cde74f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById(\"b8d3efdd-9053-4867-b3e2-5e1606cde74f\")) {                    Plotly.newPlot(                        \"b8d3efdd-9053-4867-b3e2-5e1606cde74f\",                        [{\"line\":{\"width\":6},\"marker\":{\"size\":4},\"mode\":\"lines+markers\",\"name\":\"man\",\"x\":[0,1],\"y\":[0,1],\"z\":[0,1],\"type\":\"scatter3d\"},{\"line\":{\"width\":6},\"marker\":{\"size\":4},\"mode\":\"lines+markers\",\"name\":\"monarch\",\"x\":[0,2],\"y\":[0,-1],\"z\":[0,1],\"type\":\"scatter3d\"},{\"line\":{\"width\":6},\"marker\":{\"size\":4},\"mode\":\"lines+markers\",\"name\":\"king\",\"x\":[0,3],\"y\":[0,0],\"z\":[0,2],\"type\":\"scatter3d\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermap\":[{\"type\":\"scattermap\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"scene\":{\"xaxis\":{\"title\":{\"text\":\"X\"}},\"yaxis\":{\"title\":{\"text\":\"Y\"}},\"zaxis\":{\"title\":{\"text\":\"Z\"}},\"aspectmode\":\"cube\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('b8d3efdd-9053-4867-b3e2-5e1606cde74f');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import plotly.io as pio\n",
    "\n",
    "pio.renderers.default = 'notebook_connected'  # or 'iframe' if VS Code acts up\n",
    "\n",
    "# Define origins and vectors\n",
    "origins = np.array([[0, 0, 0], [0, 0, 0],[0, 0, 0]])\n",
    "vectors = np.array([[1, 1, 1], [2,-1, 1],[3,0,2]])\n",
    "\n",
    "fig = go.Figure()\n",
    "legend_names = [\"man\", \"monarch\", \"king\"]\n",
    "\n",
    "for o, v, name in zip(origins, vectors, legend_names):\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=[o[0], o[0] + v[0]],\n",
    "        y=[o[1], o[1] + v[1]],\n",
    "        z=[o[2], o[2] + v[2]],\n",
    "        mode='lines+markers',\n",
    "        line=dict(width=6),\n",
    "        marker=dict(size=4),\n",
    "        name=name\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis_title='X',\n",
    "        yaxis_title='Y',\n",
    "        zaxis_title='Z',\n",
    "        aspectmode='cube'\n",
    "    ),\n",
    "\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8974d1a5",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Imagine the blue and red vectors represent the words 'monarch' and 'man', now, theoretically, if we add these two vectors together, we could expect the resulting vector to be a combination of the two words' meanings. \n",
    "So our resultant vector might be the embedding green of the token for 'king'. This does work for some examples, however the way that the embeddings have meanings encoded in them is not always this clear, and interactions between words can be tricky. The mathematical tool that is usually used to analyse the similarity between two embeddings should be familiar from your maths classes, being cosine similarity. Cosine similarity computes the dot product between two vectors and divides it by the product of their magnitudes, resulting in a measure of similarity between 0 and 1:\n",
    "$$\n",
    "\\text{cosine\\_similarity}(A, B) = \\frac{A \\cdot B}{\\|A\\| \\, \\|B\\|} \\\\\n",
    "\\text{where:}\\\\\n",
    "A \\cdot B = \\sum_{i=1}^{n} A_i B_i, \\\\\n",
    "\\|A\\| = \\sqrt{\\sum_{i=1}^{n} A_i^2}, \\quad\n",
    "\\|B\\| = \\sqrt{\\sum_{i=1}^{n} B_i^2}\n",
    "$$  \n",
    "\n",
    " For our RAG purposes, this enables us to use a clustering algorithm to identify topics (clusters of chunk embeddings) that are related to our prompt. \n",
    "\n",
    "If you are keen for more visual explanantion of these embeddings, check out 3blue1brown's explanation using the visual libary Manim on [youtube](https://youtu.be/wjZofJX0v4M?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&t=753)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816fb10d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Below is an example of creating and comparing embeddings using the gensim library, feel free to change the code and test different embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5ae947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader\n",
    "model = gensim.downloader.load(\"glove-wiki-gigaword-50\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e955386d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between 'king' and 'monarch': 0.71930116\n",
      "Cosine Similarity between 'king' and 'man': 0.5309377\n",
      "Cosine Similarity between 'king' and 'monarch + man': 0.74011725\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "king_embedding = model[\"king\"]\n",
    "monarch_embedding = model[\"monarch\"]\n",
    "man_embedding = model[\"man\"]\n",
    "monarch_plus_man_embedding = monarch_embedding + man_embedding\n",
    "cosine_similarity_king_with_monarch = np.dot(king_embedding, monarch_embedding) / (norm(king_embedding) * norm(monarch_embedding))\n",
    "cosine_similarity_king_with_man = np.dot(king_embedding, man_embedding) / (norm(king_embedding) * norm(man_embedding))\n",
    "cosine_similarity_king_with_monarch_plus_man = np.dot(king_embedding, monarch_plus_man_embedding) / (norm(king_embedding) * norm(monarch_plus_man_embedding))\n",
    "print(\"Cosine Similarity between 'king' and 'monarch':\", cosine_similarity_king_with_monarch)\n",
    "print(\"Cosine Similarity between 'king' and 'man':\", cosine_similarity_king_with_man)\n",
    "print(\"Cosine Similarity between 'king' and 'monarch + man':\", cosine_similarity_king_with_monarch_plus_man)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217ced38",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "As you can hopefully see, the embeddings roughly track our theory, as for the example king, monarch and man, the most similarity can be obvserved between the embedding for king, and the sum of the embeddings for man and monarch. However our similarity score is not 1, it's only 0.74, this is because the way language is used doesn't track exactly for addition, that is king does not literally mean man + monarch. There is a lot more going on with these embeddings which isn't always clear and is not the focus of our workshop."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
